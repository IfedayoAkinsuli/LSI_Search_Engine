{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ifeda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ifeda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ifeda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Parses and stores all 7 texts for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url_list = [\n",
    "    \"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%201%20-%20The%20Philosopher's%20Stone.txt\",\"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%202%20-%20The%20Chamber%20of%20Secrets.txt\",\"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%203%20-%20The%20Prisoner%20of%20Azkaban.txt\",\"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%204%20-%20The%20Goblet%20of%20Fire.txt\",\"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%205%20-%20The%20Order%20of%20the%20Phoenix.txt\",\n",
    "    \"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%206%20-%20The%20Half%20Blood%20Prince.txt\",\n",
    "    \"https://raw.githubusercontent.com/formcept/whiteboard/master/nbviewer/notebooks/data/harrypotter/Book%207%20-%20The%20Deathly%20Hallows.txt\"\n",
    "    ]\n",
    "\n",
    "text = []\n",
    "\n",
    "for _,i in enumerate(url_list):\n",
    "    req = requests.get(i)\n",
    "    text.append(req.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    text = tokenizer.tokenize(text)\n",
    "\n",
    "    lower_filter = [w.lower() for w in text]\n",
    "    filtered_text = []\n",
    "\n",
    "    filtered_text = [i for i in filtered_text if not i.isdigit()]\n",
    "\n",
    "    stop_words = stopwords.words('english') + [' j ','page','k','said','rowling','quot','back','mr','mrs']\n",
    "\n",
    "    for words in lower_filter:\n",
    "        if words not in stop_words:\n",
    "            filtered_text.append(words)\n",
    "\n",
    "    filtered_text = [i for i in filtered_text if not i.isdigit()]\n",
    "\n",
    "    lem = WordNetLemmatizer()\n",
    "\n",
    "    filtered_text = [lem.lemmatize(w) for w in filtered_text]\n",
    "\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "processed = [preprocessing(i) for _,i in enumerate(text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Query Processor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "def query_processing(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    processed_query = tokenizer.tokenize(text)\n",
    "\n",
    "    processed_query = [w.lower() for w in processed_query]\n",
    "\n",
    "    return processed_query"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Queries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "queries = [\"Who is the ghost that haunts the Hogwarts girls' bathroom?\",\"Which animal is the Patronus of Severus Snape?\",\"Who was the Defense Against the Dark Arts teacher in Harry's third year at Hogwarts\",\"Who was the founder of Slytherin House and what was his gifts\",\"What is the name of the spell that causes an object to rise and move according to the caster's will?\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "data": {
      "text/plain": "['who',\n 'is',\n 'the',\n 'ghost',\n 'that',\n 'haunts',\n 'the',\n 'hogwarts',\n 'girls',\n 'bathroom']"
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_queries = [query_processing(i) for _,i in enumerate(queries)]\n",
    "processed_queries[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The Bag of Words representing the first book"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "data": {
      "text/plain": "['boy',\n 'lived',\n 'dursley',\n 'number',\n 'four',\n 'privet',\n 'drive',\n 'proud',\n 'say',\n 'perfectly']"
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed[0][:10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare the Corpus and Indexing to form Doc-Term-Matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "X = Dictionary(processed)\n",
    "\n",
    "doc_term_matrix = [X.doc2bow(doc) for doc in processed]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Implementing the LSI Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "from gensim.models import LsiModel\n",
    "lsi_model = LsiModel(corpus=doc_term_matrix,num_topics=7,id2word=X)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7 Key topics Corresponding with each book"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "data": {
      "text/plain": "[(0,\n  '0.721*\"harry\" + 0.208*\"ron\" + 0.199*\"potter\" + 0.185*\"hermione\" + 0.159*\"j\" + 0.117*\"dumbledore\" + 0.098*\"could\" + 0.092*\"know\" + 0.090*\"one\" + 0.082*\"like\"'),\n (1,\n  '0.488*\"order\" + 0.464*\"phoenix\" + -0.239*\"harry\" + 0.229*\"umbridge\" + 0.219*\"sirius\" + -0.176*\"hallows\" + -0.169*\"deathly\" + -0.130*\"prince\" + -0.122*\"blood\" + 0.121*\"professor\"'),\n (2,\n  '0.403*\"fire\" + 0.389*\"goblet\" + -0.264*\"hallows\" + -0.254*\"deathly\" + -0.179*\"blood\" + -0.170*\"prince\" + -0.164*\"half\" + 0.152*\"moody\" + 0.147*\"crouch\" + -0.127*\"dumbledore\"'),\n (3,\n  '-0.374*\"prince\" + -0.354*\"blood\" + 0.352*\"hallows\" + -0.348*\"half\" + 0.338*\"deathly\" + -0.242*\"dumbledore\" + -0.181*\"slughorn\" + 0.169*\"hermione\" + 0.166*\"wand\" + -0.141*\"malfoy\"'),\n (4,\n  '0.300*\"azkaban\" + 0.292*\"prisoner\" + -0.273*\"fire\" + -0.268*\"goblet\" + -0.221*\"dumbledore\" + 0.204*\"lupin\" + 0.194*\"black\" + 0.171*\"professor\" + 0.153*\"harry\" + 0.138*\"ron\"'),\n (5,\n  '-0.373*\"chamber\" + -0.338*\"secret\" + 0.324*\"azkaban\" + 0.302*\"prisoner\" + 0.257*\"lupin\" + 0.198*\"hermione\" + -0.187*\"lockhart\" + 0.186*\"black\" + -0.184*\"stone\" + -0.146*\"philosopher\"'),\n (6,\n  '0.450*\"stone\" + 0.386*\"philosopher\" + -0.296*\"chamber\" + -0.281*\"secret\" + 0.246*\"hagrid\" + -0.158*\"lockhart\" + -0.155*\"ron\" + 0.126*\"quirrell\" + 0.124*\"dudley\" + -0.110*\"dobby\"')]"
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi_model.print_topics()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convert the Query into LSI Space"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.03491504088121482), (1, -0.026611678787924493), (2, 0.028591680955725864), (3, -0.021295612037152935), (4, 0.009907197298940884), (5, -0.06193307475850284), (6, -0.007823154196609757)]\n"
     ]
    }
   ],
   "source": [
    "indexed_query = [Dictionary(processed).doc2bow(j) for j in processed_queries]\n",
    "vector_query = [lsi_model[a] for a in indexed_query]\n",
    "print(vector_query[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Matrix Similarity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "from gensim import similarities\n",
    "index = similarities.MatrixSimilarity(lsi_model[doc_term_matrix])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Perform Ranking"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [],
   "source": [
    "def doc_ranking_score(vector_query):\n",
    "    similarities = index[vector_query]\n",
    "\n",
    "    for i in similarities:\n",
    "        t = np.argpartition(i,-4)[-4:]\n",
    "        sol = i[t]\n",
    "        sol = (list(t+1),list(sol[::-1]))\n",
    "        print(f'The most relevant books in descending order are {sol[0]} with similarity scores of {sol[1]} ')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most relevant books in descending order are [6, 4, 2, 1] with similarity scores of [0.52452683, 0.6451366, 0.47689116, 0.44063973] \n",
      "The most relevant books in descending order are [7, 3, 6, 1] with similarity scores of [0.4560766, 0.49757794, 0.53445834, 0.41275486] \n",
      "The most relevant books in descending order are [6, 4, 3, 2] with similarity scores of [0.9622794, 0.9406679, 0.9330468, 0.9219502] \n",
      "The most relevant books in descending order are [5, 4, 2, 1] with similarity scores of [0.50057507, 0.5618626, 0.3176321, 0.2952755] \n",
      "The most relevant books in descending order are [6, 1, 4, 7] with similarity scores of [0.61576915, 0.53625244, 0.51299, 0.4980296] \n"
     ]
    }
   ],
   "source": [
    "doc_ranking_score(vector_query)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate key Metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create a BM25 Implementation for Comparison....."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
